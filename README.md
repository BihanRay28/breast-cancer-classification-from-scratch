ğŸ§  Breast Cancer Classification from Scratch

End-to-end implementation of a two-layer neural network built entirely from scratch using NumPy for binary classification on the Breast Cancer Wisconsin dataset.

No high-level ML libraries were used for model training â€” only NumPy and manual implementation of neural network mathematics.

ğŸ“Œ Project Objective

The purpose of this project was to deeply understand:

Forward propagation

Backpropagation

Gradient descent

Binary cross-entropy loss

Parameter initialization

Model evaluation

Rather than using frameworks like TensorFlow or PyTorch, the model logic is implemented manually.

ğŸ— Model Architecture
Input Layer (30 features)
        â†“
Hidden Layer (8 neurons, tanh activation)
        â†“
Output Layer (1 neuron, sigmoid activation)


Loss Function:

Binary Cross Entropy

Optimization:

Gradient Descent

ğŸ“Š Results

After training for 8000 iterations:

Training Accuracy: ~98.9%

Test Accuracy: ~98.2%

The cost decreases smoothly during training, confirming stable gradient descent behavior.

ğŸ“ Project Structure
data.py       â†’ Dataset loading & preprocessing
nn_core.py    â†’ Neural network logic (forward + backward propagation)
train.py      â†’ Training loop
predict.py    â†’ Prediction function
main.py       â†’ Execution + visualization
ğŸ“š Dataset

Breast Cancer Wisconsin (Diagnostic) dataset  
- 569 samples  
- 30 numerical features  
- Binary classification (Malignant / Benign)

ğŸ§  Key Learnings

- Importance of feature normalization for stable training
- Sensitivity of convergence to learning rate
- Role of non-linearity (tanh) in improving classification
- How backpropagation propagates gradients layer-by-layer

  ğŸ”­ Next Steps

- Implement L2 regularization
- Add dropout
- Compare against logistic regression baseline
- Rebuild using PyTorch for scalability

